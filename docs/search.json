[
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "This is the first post in a Quarto blog. Welcome!\n\nSince this post doesn’t specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "A Slice of Data",
    "section": "",
    "text": "Market Segmentation with Regression Trees in R: A Step-by-Step Guide\n\n\n\n\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\nJan 13, 2025\n\n\nYeji Sohn\n\n\n\n\n\n\n\n\n\n\n\n\nWelcome To My Blog\n\n\n\n\n\n\nnews\n\n\n\n\n\n\n\n\n\nJan 10, 2025\n\n\nTristan O’Malley\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "posts/post-with-code/index.html",
    "href": "posts/post-with-code/index.html",
    "title": "Market Segmentation with Regression Trees in R: A Step-by-Step Guide",
    "section": "",
    "text": "In the world of data science, one of the most powerful tools for understanding customer behavior and improving marketing strategies is market segmentation. By dividing a market into subgroups with shared characteristics, companies can optimize pricing, enhance customer satisfaction, and allocate resources effectively. In this post, we explore how to use regression trees in R for market segmentation, providing a step-by-step guide for practical application.\n\nWhat is Market Segmentation?\nMarket segmentation divides a market into distinct customer groups with similar needs, interests, and priorities, allowing businesses to tailor marketing efforts and products. This process enhances resource allocation and customer satisfaction. For example, a retailer might segment by geography, income, or behavior. In this case, we’ll use store demographics (age, income, ethnicity) to predict sales price differences with a regression tree model.\n\n\nKey Concepts to Understand\n\nRegression Trees: A machine learning tool that predicts continuous outcomes by splitting data based on input features.\nCP Value: Complexity Parameter decides how deep the decision tree will be grown into. If any split does not increase the overall R2 of the model by at least cp, the tree does not split said branch any further\n\n\n\nSample Dataset\ndataset is from: Alice Project\nThere are around 10,000 observations and 9 continuous and categorical variables representing user’s behaviors and characteristics.\nDescription of varaibales are as following:\n\n\n\n\n\n\n\nFeature Name\nDetails\n\n\n\n\naccount_age\nuser’s account age\n\n\nage\nuser’s age\n\n\navg_hours\nthe average hours user was online per week in the past\n\n\ndays_visited\nthe average number of days user visited the website per week\n\n\nfriend_count\nnumber of friends of user’s account\n\n\nhas_membership\nwhether the user had membership\n\n\nis_US\nwhether the user accesses the website from the United States\n\n\nsongs_purchased\nthe average songs user purchased per week (non-discount season)\n\n\nincome\nuser’s income\n\n\nprice\nthe price user was exposed to during the discount season (baseline price * small discount)\n\n\ndemand\nsongs user purchased during the discount season\n\n\n\n\n\nStep-by-Step Guide\nThis guide is adapted from EconML\n\nStep 1: Loading and Preparing the Data\nFirst, we load the libraries and data, and perform some basic data cleaning.\nimport pandas as pd\nimport numpy as np\nimport statsmodels.api as sm\nimport statsmodels.formula.api as smf\nfrom sklearn.tree import DecisionTreeRegressor\nimport matplotlib.pyplot as plt\nfrom sklearn.tree import plot_tree\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn import tree\n\nog_df = pd.read_csv(\"https://msalicedatapublic.z5.web.core.windows.net/datasets/Pricing/pricing_sample.csv\")\nog_df.columns = og_df.columns.str.replace(' ', '_').str.lower()  # Clean column names\n\n\nStep 2: Choose number of segments\nIn this step, we use a regression tree to identify how many segments (or clusters) we want. The tree’s complexity is controlled by a hyperparameter (ccp_alpha), which we adjust to visualize the tree structure at different levels of complexity.\ndef show_tree(cp_val, data):\n    reg_tree = DecisionTreeRegressor(ccp_alpha=cp_val)\n    reg_tree.fit(data.drop(columns='demand'), data['demand'])\n\n    plt.figure(figsize=(20,10))\n    tree.plot_tree(reg_tree, filled=True, feature_names=data.drop(columns='demand').columns)\n    plt.show()\n\npricing_df = og_df.copy()\n\n# exclude variable of intersts for segmentation\nreg_tree_data = pricing_df.drop(columns=['price'])\nshow_tree(5, reg_tree_data)\n\n\n\nTree5\n\n\nshow_tree(1, reg_tree_data)\n\n\n\nTree1\n\n\nWe want 4 segments, so we will proceed with cp value of 1.\n\n\nStep 3: Building the Regression Tree\nIn this step, we build the actual regression tree model, training it on the user characteristics to predict the demand.\ncp_val = 1\nreg_tree = DecisionTreeRegressor(ccp_alpha=cp_val)\nreg_tree.fit(reg_tree_data.drop(columns='demand'), reg_tree_data['demand'])\nBy fitting the model, we are able to identify the relationships between the various user characteristics and demand, and the tree automatically creates splits (segments) based on these variables.\n\n\nStep 4: Assigning Stores to Leaves\nNext, we assign each user to a regression tree leaf:\npricing_df['leaf'] = reg_tree.apply(reg_tree_data.drop(columns='demand'))\nThis step adds a new variable leaf to the dataset, which indicates the leaf (or segment) that each user belongs to.\n\n\nStep 5: Interpreting the Results\nAt this point, we have successfully segmented the users based on their characteristics. Each user is now assigned to a segment (leaf) that represents a group of stores with similar characteristics.\nTo calculate price elasticities for each segment, do the following:\npricing_df['log_price'] = np.log(pricing_df['price'])\npricing_df['log_q'] = np.log(pricing_df['demand'])\ndata = []\n\n# Elasticity function\ndef own_price_reg(leaf_num):\n    df  = pricing_df[pricing_df['leaf'] == leaf_num]\n    model = smf.ols('log_q ~ log_price', data=df).fit()\n    return model.params['log_price']\n\nfor leaf in pricing_df['leaf'].unique():\n    own_price = own_price_reg(leaf)\n    leaf_data = pricing_df[pricing_df['leaf'] == leaf]\n    avg_values = leaf_data.drop(columns=['leaf']).mean().to_dict()\n    \n    # Add the result to the data list\n    avg_values['leaf'] = leaf\n    avg_values['own_price_reg'] = own_price\n    data.append(avg_values)\n\npd.DataFrame(data)\nBoth price and demand are transformed by log. This allows the coefficients to represent elasticity (the percentage change in demand for a percentage change in price).\n\nimport pandas as pd\nfrom IPython.display import Markdown\nfrom tabulate import tabulate\nresults = pd.read_csv(\"../../results/tbl/elasticity.csv\")\n\nMarkdown(results.to_markdown(index = False))\n\n\n\nTable 1: Average features and elasticity by segmentation\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nindex\naccount_age\nage\navg_hours\ndays_visited\nfriends_count\nhas_membership\nis_us\nsongs_purchased\nincome\nprice\ndemand\nlog_price\nlog_q\nleaf\nown_price_reg\n\n\n\n\n0\n3.01726\n38.9238\n5.07327\n1.94948\n10.0314\n0.49294\n0.800439\n5.10132\n0.697376\n0.867587\n7.78766\n-0.145771\n2.02731\n2\n-2.14204\n\n\n1\n2.97933\n39.4955\n5.05556\n5.99788\n9.97509\n0.514043\n0.786963\n4.98314\n0.702922\n0.869104\n12.753\n-0.144278\n2.53648\n3\n-1.27903\n\n\n2\n2.99316\n38.5003\n4.97012\n6.00526\n10.07\n0.50868\n0.793793\n5.14311\n1.5587\n0.958127\n24.6107\n-0.0454373\n3.20234\n6\n-0.112743\n\n\n3\n3.01388\n38.797\n4.93473\n2.01388\n10.0212\n0.488926\n0.807273\n4.9841\n1.57671\n0.958446\n19.592\n-0.0450707\n2.9738\n5\n-0.1203\n\n\n\n\n\n\n\n\nGroup 2:\n\nPrice Elasticity (-2.14): Highly elastic, meaning demand is sensitive to price changes. A small price increase could significantly reduce demand.\nAverage Income (0.70): Relatively low compared to other groups, suggesting higher price sensitivity (income effect).\nAverage Days Visited (1.95): Low platform engagement, possibly contributing to higher elasticity as these users might not be habitual buyers.\nInterpretation: Price adjustments could significantly impact demand in this group, requiring careful consideration of pricing strategies.\n\nGroup 3:\n\nPrice Elasticity (-1.28): Moderately elastic, indicating that users are still responsive to price changes, but less so than Group 0.\nAverage Income (0.70): Similar to Group 2, maintaining moderate price sensitivity.\nAverage Days Visited (5.99): Higher engagement than Group 0, which could reduce elasticity as these users are more invested in the platform.\nInterpretation: This group may respond to price changes, but their higher engagement suggests potential for retention despite price increases.\n\nGroup 6:\n\nPrice Elasticity (-0.11): Nearly inelastic, indicating demand is relatively insensitive to price changes.\nIncome (1.56): Higher than the other groups, likely contributing to lower price sensitivity.\nAverage Days Visited (6.01): Highest engagement, which could reduce elasticity as these users are more invested in the platform. highly.\nInterpretation: This group can tolerate higher prices without significant reductions in demand, making them ideal for premium offerings.\n\nGroup 5:\n\nPrice Elasticity (-0.12): Nearly inelastic, similar to Group 6.\nIncome (1.58): Comparable to Group 6, supporting lower price sensitivity.\nAverage Days Visited (2.01): Despite low platform engagement, demand (19.59) remains high, indicating users in this group value the product highly.\nInterpretation: Like Group 6, this group is less price-sensitive and may represent another target for premium pricing or tailored offers.\n\nRecommendation: 1. High Elasticity Groups (2 and 3): - These groups are more price-sensitive due to lower income, engagement, or both. - Price reductions or promotions may drive significant demand increases.\n\nLow Elasticity Groups (6 and 5):\n\nThese groups show low sensitivity to price changes, likely due to higher income and inherent demand.\nThey are suitable candidates for price increases or premium-tier products.\n\n\nBy understanding these nuances, pricing and marketing strategies can be tailored to maximize revenue while maintaining user satisfaction.\n\n\n\nReal-World Applications\nMarket segmentation using regression trees can be applied to a variety of industries. Here are a few examples:\n\nRetail: Optimize promotions and product offerings based on customer demographics.\nHealthcare: Segment patients to tailor treatment plans.\nFinance: Offer personalized financial products based on income and behavior.\n\n\n\nConclusion\nIn this blog post, we demonstrated how to segment a market using regression trees in R. By using regression trees for segmentation, you can uncover actionable insights to drive strategy and decision-making. Whether refining pricing strategies or identifying customer needs, these tools offer a robust way to make the most of your data.\nKey takeaways include: - Market segmentation is essential for understanding and targeting specific customer groups. - Regression trees are an effective tool for predicting continuous outcomes based on various independent variables. - By segmenting stores based on their demographics, retailers can optimize pricing and improve sales strategies.\nIf you’re interested in diving deeper into regression trees or market segmentation, try applying these techniques to your own datasets and explore how different groups behave differently in your industry."
  },
  {
    "objectID": "report/pricing_py.html",
    "href": "report/pricing_py.html",
    "title": "Blog",
    "section": "",
    "text": "import pandas as pd\nimport numpy as np\nimport statsmodels.api as sm\nimport statsmodels.formula.api as smf\nfrom sklearn.tree import DecisionTreeRegressor\nimport matplotlib.pyplot as plt\nfrom sklearn.tree import plot_tree\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn import tree\n\nog_df = pd.read_csv(\"https://msalicedatapublic.z5.web.core.windows.net/datasets/Pricing/pricing_sample.csv\")\nog_df.columns = og_df.columns.str.replace(' ', '_').str.lower()  # Clean column names\n\n\ndef show_tree(cp_val):\n    reg_tree = DecisionTreeRegressor(ccp_alpha=cp_val)\n    reg_tree.fit(reg_tree_data.drop(columns='demand'), reg_tree_data['demand'])\n\n    plt.figure(figsize=(20,10))\n    tree.plot_tree(reg_tree, filled=True, feature_names=reg_tree_data.drop(columns='demand').columns)\n    plt.show()\n\npricing_df = og_df.copy()\n\nreg_tree_data = pricing_df.drop(columns=['price', 'has_membership', 'is_us'])\n\nshow_tree(5)\n\n\n\n\n\n\n\n\n\nshow_tree(1)\n\n\n\n\n\n\n\n\n\ncp_val = 1\nreg_tree = DecisionTreeRegressor(ccp_alpha=cp_val)\nreg_tree.fit(reg_tree_data.drop(columns='demand'), reg_tree_data['demand'])\n\nDecisionTreeRegressor(ccp_alpha=1)In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.DecisionTreeRegressor?Documentation for DecisionTreeRegressoriFittedDecisionTreeRegressor(ccp_alpha=1) \n\n\n\npricing_df\n\n\n  \n    \n\n\n\n\n\n\naccount_age\nage\navg_hours\ndays_visited\nfriends_count\nhas_membership\nis_us\nsongs_purchased\nincome\nprice\ndemand\n\n\n\n\n0\n3\n53\n1.834234\n2\n8\n1\n1\n4.903237\n0.960863\n1.0\n3.917117\n\n\n1\n5\n54\n7.171411\n7\n9\n0\n1\n3.330161\n0.732487\n1.0\n11.585706\n\n\n2\n3\n33\n5.351920\n6\n9\n0\n1\n3.036203\n1.130937\n1.0\n24.675960\n\n\n3\n2\n34\n6.723551\n0\n8\n0\n1\n7.911926\n0.929197\n1.0\n6.361776\n\n\n4\n4\n30\n2.448247\n5\n8\n1\n0\n7.148967\n0.533527\n0.8\n12.624123\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n9995\n2\n56\n6.095439\n3\n10\n0\n0\n7.406568\n0.545599\n0.8\n9.447720\n\n\n9996\n3\n52\n7.828183\n7\n5\n0\n1\n0.782374\n0.944415\n0.8\n15.314092\n\n\n9997\n1\n27\n6.527350\n6\n9\n0\n1\n10.926441\n0.815953\n1.0\n11.263675\n\n\n9998\n4\n49\n2.803943\n6\n9\n1\n1\n4.205016\n0.504313\n0.8\n12.801971\n\n\n9999\n5\n35\n9.334821\n2\n9\n0\n1\n2.971992\n1.456270\n1.0\n21.667410\n\n\n\n\n10000 rows × 11 columns\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n\n  \n\n\n    \n        \n    \n\n  \n\n\n\n  \n\n\n  \n    \n    \n\n  \n    \n  \n    \n    \n  \n\n    \n  \n\n\n\npricing_df['leaf'] = reg_tree.apply(reg_tree_data.drop(columns='demand'))\n\n# Elasticity function\ndef own_price_reg(leaf_num):\n    df  = pricing_df[pricing_df['leaf'] == leaf_num]\n    model = smf.ols('demand ~ price * has_membership * is_us', data=df).fit()\n    return model.params['price']\n\nelasticities = [own_price_reg(leaf) for leaf in pricing_df['leaf'].unique()]\nprint(elasticities)\n\n[-18.265984327571324, -18.17187119271577, -5.235805786421214, -1.4067338547890245]"
  }
]